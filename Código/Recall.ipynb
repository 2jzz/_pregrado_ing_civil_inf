{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import random as rn\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading de los modelos.\n",
    "\n",
    "# Ruta donde están los modelos.\n",
    "\n",
    "model_CDM = load_model(filepath = \"../Versión 3 - actual/modelos/datasetCDM_2023_04_17_19_35\")\n",
    "\n",
    "model_GRD = load_model(filepath = \"../Versión 3 - actual/modelos/datasetGRD_2023_04_17_20_53\")\n",
    "\n",
    "model_GRDT = load_model(filepath = \"../Versión 3 - actual/modelos/datasetGRDT_2023_04_17_11_29\")\n",
    "\n",
    "model_SEV = load_model(filepath = \"../Versión 3 - actual/modelos/datasetSEV_2023_04_17_22_09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../../../Datos/Procesados/x_values.csv\", dtype = int)\n",
    "y_cdm = pd.read_csv(\"../../../Datos/Procesados/y_dummies_cdm.csv\", dtype = int)\n",
    "y_grdt = pd.read_csv(\"../../../Datos/Procesados/y_dummies_grdtipo.csv\", dtype = int)\n",
    "y_grd = pd.read_csv(\"../../../Datos/Procesados/y_dummies_grd.csv\", dtype = int)\n",
    "y_sev = pd.read_csv(\"../../../Datos/Procesados/y_dummies_sev.csv\", dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_grd\n",
    "y_str = 'GRD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 0, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11900/11900 [==============================] - 24s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model_GRD.predict(x_test)\n",
    "\n",
    "# score = model_GRDT.evaluate(x_test, y_test, verbose = 1, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = y_test.to_numpy(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_labels = y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se hizo porque hay una clase que no tiene datos en el recorte, entonces tira problemas el gráficado del recall. (38 si mal no recuerdo)\n",
    "\n",
    "class_labels = ['1', '2', '3', '4', '5', '6', '7', '8', '10', '11', '12', '13', '14',\n",
    "       '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
    "       '27', '29', '30', '31', '32', '33', '34', '35', '36', '37', '40',\n",
    "       '41', '42', '43', '44', '50', '51', '52', '53', '60', '61', '62', '63',\n",
    "       '64', '65', '70', '71', '72', '80', '81', '82', '83', '84']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_prediction, axis = 1, keepdims = True)\n",
    "y_true_classes = np.argmax(y_test_np, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_per_class = recall_score(y_true_classes, y_pred_classes, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recall_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recall_plots(recall_per_class, class_labels, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    num_classes = len(class_labels)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.bar(0, recall_per_class[i], color='blue')\n",
    "        plt.xticks([])\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel('Recall')\n",
    "        plt.title(f'Recall de la Clase {class_labels[i]}')\n",
    "        plt.savefig(os.path.join(output_folder, f'recall_class_{class_labels[i]}.png'), bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recall_plots_2(recall_per_class, class_labels, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    num_classes = len(class_labels)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot([0, 1], [recall_per_class[i], recall_per_class[i]], color='blue', linewidth=2)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel('Recall')\n",
    "        plt.title(f'Recall de la Clase {class_labels[i]}')\n",
    "        plt.savefig(os.path.join(output_folder, f'recall_class_{class_labels[i]}.png'), bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = f'../../../Visualización de datos/Recall/{y_str}/'\n",
    "\n",
    "save_recall_plots_2(recall_per_class, class_labels, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true_classes son las etiquetas verdaderas convertidas a clases\n",
    "# y_pred_classes son las etiquetas predichas convertidas a clases\n",
    "\n",
    "# Calcular el recall promedio ponderado\n",
    "recall_weighted = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "print(\"Recall promedio ponderado:\", recall_weighted)\n",
    "\n",
    "# Calcular el recall promedio macro\n",
    "recall_macro = recall_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(\"Recall promedio macro:\", recall_macro)\n",
    "\n",
    "# Calcular el recall promedio micro\n",
    "recall_micro = recall_score(y_true_classes, y_pred_classes, average='micro')\n",
    "print(\"Recall promedio micro:\", recall_micro)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
